{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkH4ob1HyLy58XdbtCTxWq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hirajya/Handling-Imbalance-dataset/blob/main/ANN_%7C_Handling_Imbalance_dataset_techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwQrEZvWLBAc",
        "outputId": "0691963a-a96d-4c2d-aee9-8037ed01d7d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "syCrNUatMIlU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/datasets/Churn_Modelling_Cleaned.csv'\n",
        "\n",
        "df = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "DLPUKPOILTFj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2Zz5VLxDMNkn",
        "outputId": "1ebaeee1-668c-44cb-b92e-deebbc0ab228"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CreditScore  Gender       Age  Tenure   Balance  HasCrCard  IsActiveMember  \\\n",
              "0        0.538       0  0.324324     0.2  0.000000          1               1   \n",
              "1        0.516       0  0.310811     0.1  0.334031          0               1   \n",
              "2        0.304       0  0.324324     0.8  0.636357          1               0   \n",
              "3        0.698       0  0.283784     0.1  0.000000          0               0   \n",
              "4        1.000       0  0.337838     0.2  0.500246          1               1   \n",
              "\n",
              "   EstimatedSalary  Exited  NumOfProducts_1  NumOfProducts_2  NumOfProducts_3  \\\n",
              "0         0.506735       1                1                0                0   \n",
              "1         0.562709       0                1                0                0   \n",
              "2         0.569654       1                0                0                1   \n",
              "3         0.469120       0                0                1                0   \n",
              "4         0.395400       0                1                0                0   \n",
              "\n",
              "   NumOfProducts_4  \n",
              "0                0  \n",
              "1                0  \n",
              "2                0  \n",
              "3                0  \n",
              "4                0  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-47d44689-033c-4827-8750-23869e051257\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>NumOfProducts_1</th>\n",
              "      <th>NumOfProducts_2</th>\n",
              "      <th>NumOfProducts_3</th>\n",
              "      <th>NumOfProducts_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.538</td>\n",
              "      <td>0</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.506735</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.516</td>\n",
              "      <td>0</td>\n",
              "      <td>0.310811</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.334031</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.562709</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.304</td>\n",
              "      <td>0</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.636357</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.569654</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.698</td>\n",
              "      <td>0</td>\n",
              "      <td>0.283784</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469120</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.337838</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.500246</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.395400</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47d44689-033c-4827-8750-23869e051257')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-002e287a-86f3-41cf-906e-f1a294bea13f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-002e287a-86f3-41cf-906e-f1a294bea13f')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-002e287a-86f3-41cf-906e-f1a294bea13f button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47d44689-033c-4827-8750-23869e051257 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47d44689-033c-4827-8750-23869e051257');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASMU8megMi9s",
        "outputId": "87fe297d-b54c-49e7-bea6-00d3d12e5b16"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ANN(training_inputs, loss, weights):\n",
        "  # training inputs = [X_train, X_test, y_train, y_test]\n",
        "  model = keras.Sequential([\n",
        "      keras.layers.Dense(10, input_shape=(12,), activation='relu'),\n",
        "      keras.layers.Dense(5, activation='relu'),\n",
        "      keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "      optimizer='adam',\n",
        "      loss='binary_crossentropy',\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  if weights == -1:\n",
        "    model.fit(training_inputs[0], training_inputs[2], epochs=100)\n",
        "  else:\n",
        "    model.fit(training_inputs[0], training_inputs[2], epochs=100, class_weight = weights)\n",
        "\n",
        "  print(model.evaluate(training_inputs[1], training_inputs[3]))\n",
        "\n",
        "  y_preds = model.predict(training_inputs[1])\n",
        "  y_pred = np.round(y_preds)\n",
        "\n",
        "  print(\"Classification Report: \\n\", classification_report(training_inputs[3], y_pred))\n",
        "\n",
        "  return y_preds"
      ],
      "metadata": {
        "id": "wS1EpxXOMOZF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_input(X, y):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "  return [X_train, X_test, y_train, y_test]\n"
      ],
      "metadata": {
        "id": "zNiXz_vgOVWH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EQwxAB-pPyUc",
        "outputId": "adf88593-73cd-4387-9860-615a34d0525e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CreditScore  Gender       Age  Tenure   Balance  HasCrCard  IsActiveMember  \\\n",
              "0        0.538       0  0.324324     0.2  0.000000          1               1   \n",
              "1        0.516       0  0.310811     0.1  0.334031          0               1   \n",
              "2        0.304       0  0.324324     0.8  0.636357          1               0   \n",
              "3        0.698       0  0.283784     0.1  0.000000          0               0   \n",
              "4        1.000       0  0.337838     0.2  0.500246          1               1   \n",
              "\n",
              "   EstimatedSalary  Exited  NumOfProducts_1  NumOfProducts_2  NumOfProducts_3  \\\n",
              "0         0.506735       1                1                0                0   \n",
              "1         0.562709       0                1                0                0   \n",
              "2         0.569654       1                0                0                1   \n",
              "3         0.469120       0                0                1                0   \n",
              "4         0.395400       0                1                0                0   \n",
              "\n",
              "   NumOfProducts_4  \n",
              "0                0  \n",
              "1                0  \n",
              "2                0  \n",
              "3                0  \n",
              "4                0  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-0a8f7093-dd22-4879-bb3a-72a2fb22f7ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>NumOfProducts_1</th>\n",
              "      <th>NumOfProducts_2</th>\n",
              "      <th>NumOfProducts_3</th>\n",
              "      <th>NumOfProducts_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.538</td>\n",
              "      <td>0</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.506735</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.516</td>\n",
              "      <td>0</td>\n",
              "      <td>0.310811</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.334031</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.562709</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.304</td>\n",
              "      <td>0</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.636357</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.569654</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.698</td>\n",
              "      <td>0</td>\n",
              "      <td>0.283784</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469120</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.337838</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.500246</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.395400</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a8f7093-dd22-4879-bb3a-72a2fb22f7ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-de6523d4-d90d-488d-97ae-c4e4c05785ec\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de6523d4-d90d-488d-97ae-c4e4c05785ec')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-de6523d4-d90d-488d-97ae-c4e4c05785ec button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a8f7093-dd22-4879-bb3a-72a2fb22f7ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a8f7093-dd22-4879-bb3a-72a2fb22f7ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.Exited.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m82RtUmRQYbe",
        "outputId": "0b08e948-aa7a-44cc-eb65-9213cc43cc6f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7963\n",
              "1    2037\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class count\n",
        "count_class_0, count_class_1 = df.Exited.value_counts()\n",
        "\n",
        "# divide by class\n",
        "df_class_0 = df[df['Exited'] == 0]\n",
        "df_class_1 = df[df['Exited'] == 1]"
      ],
      "metadata": {
        "id": "Dob315DHQiQs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test; Control model"
      ],
      "metadata": {
        "id": "MFGjebHEOMBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Exited', axis=1)\n",
        "y = df['Exited']"
      ],
      "metadata": {
        "id": "Zf_cg3oLPwpN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = train_input(X, y)"
      ],
      "metadata": {
        "id": "QDuW5J-lOHyy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_m0 = ANN(inputs, 'binary_crossentropy', -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT_uFbGaP_-p",
        "outputId": "dc409ecf-37f2-4abe-883a-c9574904ace6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 1s 1ms/step - loss: 0.5101 - accuracy: 0.7894\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.8046\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4119 - accuracy: 0.8246\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3991 - accuracy: 0.8314\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3914 - accuracy: 0.8345\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3851 - accuracy: 0.8396\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3820 - accuracy: 0.8399\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3775 - accuracy: 0.8424\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3754 - accuracy: 0.8447\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 0s 1000us/step - loss: 0.3733 - accuracy: 0.8438\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3720 - accuracy: 0.8445\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3714 - accuracy: 0.8468\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3699 - accuracy: 0.8466\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3688 - accuracy: 0.8476\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.8478\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3670 - accuracy: 0.8481\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3663 - accuracy: 0.8493\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3658 - accuracy: 0.8511\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3647 - accuracy: 0.8500\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3641 - accuracy: 0.8505\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3647 - accuracy: 0.8487\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3635 - accuracy: 0.8504\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3636 - accuracy: 0.8503\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3625 - accuracy: 0.8499\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 0s 976us/step - loss: 0.3627 - accuracy: 0.8516\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 0s 993us/step - loss: 0.3623 - accuracy: 0.8500\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3621 - accuracy: 0.8489\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3616 - accuracy: 0.8521\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3614 - accuracy: 0.8524\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8500\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3619 - accuracy: 0.8515\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.8521\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3612 - accuracy: 0.8534\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8537\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3608 - accuracy: 0.8521\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8512\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3607 - accuracy: 0.8531\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.8529\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3604 - accuracy: 0.8518\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3600 - accuracy: 0.8522\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3604 - accuracy: 0.8530\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8516\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3595 - accuracy: 0.8541\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3604 - accuracy: 0.8531\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8529\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8519\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3596 - accuracy: 0.8534\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3604 - accuracy: 0.8544\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3595 - accuracy: 0.8543\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8536\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3591 - accuracy: 0.8543\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3593 - accuracy: 0.8549\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8544\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8533\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3604 - accuracy: 0.8525\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3594 - accuracy: 0.8543\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3594 - accuracy: 0.8530\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3596 - accuracy: 0.8540\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3592 - accuracy: 0.8556\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8547\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3600 - accuracy: 0.8539\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3594 - accuracy: 0.8549\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8547\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8555\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3587 - accuracy: 0.8551\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3589 - accuracy: 0.8533\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3594 - accuracy: 0.8553\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8553\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8558\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8544\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8544\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3589 - accuracy: 0.8535\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8547\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8566\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3592 - accuracy: 0.8559\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3586 - accuracy: 0.8560\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3591 - accuracy: 0.8554\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3580 - accuracy: 0.8550\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3584 - accuracy: 0.8554\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8555\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3584 - accuracy: 0.8558\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3584 - accuracy: 0.8562\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8551\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3578 - accuracy: 0.8564\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3581 - accuracy: 0.8564\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3576 - accuracy: 0.8561\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8550\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3575 - accuracy: 0.8571\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.8555\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3576 - accuracy: 0.8570\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3575 - accuracy: 0.8558\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8564\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3574 - accuracy: 0.8555\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8566\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3574 - accuracy: 0.8558\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3571 - accuracy: 0.8550\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3564 - accuracy: 0.8558\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3567 - accuracy: 0.8559\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8549\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3566 - accuracy: 0.8561\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3524 - accuracy: 0.8585\n",
            "[0.35242709517478943, 0.8585000038146973]\n",
            "63/63 [==============================] - 0s 734us/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.98      0.92      1593\n",
            "           1       0.82      0.39      0.53       407\n",
            "\n",
            "    accuracy                           0.86      2000\n",
            "   macro avg       0.84      0.68      0.72      2000\n",
            "weighted avg       0.85      0.86      0.84      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_class_0, count_class_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCRgD2zNQ79_",
        "outputId": "e6a2f805-a477-45d2-c97f-bea34d894bd9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7963, 2037)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_class_0.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H2OVRbPQ9oI",
        "outputId": "f382efb0-496e-48c5-92cb-830c7816d249"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7963, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_class_1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WvJ4sY7Q-YW",
        "outputId": "5f5666a8-fe96-4b8d-b20f-eece5ba009f9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2037, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 1: Undersampling"
      ],
      "metadata": {
        "id": "647dd6bCQu5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_class_0_under = df_class_0.sample(count_class_1)\n",
        "df_class_0_under.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4_MYlVOQP-l",
        "outputId": "447f9850-65cc-4ec3-af2d-5544eab7112f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2037, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_class_0_under[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "atq4OJhMRF_7",
        "outputId": "b72521ca-4521-47c4-c56a-0274ff8d7751"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CreditScore  Gender       Age  Tenure   Balance  HasCrCard  \\\n",
              "4666        1.000       0  0.283784     0.5  0.456328          1   \n",
              "5145        0.868       1  0.270270     0.1  0.552077          1   \n",
              "7325        0.822       0  0.216216     0.2  0.000000          1   \n",
              "1530        0.522       0  0.108108     0.2  0.428496          1   \n",
              "4820        0.268       0  0.189189     0.3  0.000000          1   \n",
              "\n",
              "      IsActiveMember  EstimatedSalary  Exited  NumOfProducts_1  \\\n",
              "4666               0         0.498437       0                1   \n",
              "5145               1         0.858868       0                1   \n",
              "7325               0         0.306228       0                0   \n",
              "1530               1         0.604008       0                0   \n",
              "4820               1         0.696964       0                0   \n",
              "\n",
              "      NumOfProducts_2  NumOfProducts_3  NumOfProducts_4  \n",
              "4666                0                0                0  \n",
              "5145                0                0                0  \n",
              "7325                1                0                0  \n",
              "1530                1                0                0  \n",
              "4820                1                0                0  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-fde315c5-a44b-417a-9e70-3c7b086074f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>NumOfProducts_1</th>\n",
              "      <th>NumOfProducts_2</th>\n",
              "      <th>NumOfProducts_3</th>\n",
              "      <th>NumOfProducts_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4666</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.283784</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.456328</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.498437</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>0.868</td>\n",
              "      <td>1</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.552077</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.858868</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7325</th>\n",
              "      <td>0.822</td>\n",
              "      <td>0</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.306228</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1530</th>\n",
              "      <td>0.522</td>\n",
              "      <td>0</td>\n",
              "      <td>0.108108</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.428496</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.604008</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4820</th>\n",
              "      <td>0.268</td>\n",
              "      <td>0</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.696964</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fde315c5-a44b-417a-9e70-3c7b086074f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-415d1b2f-5718-4d1f-acb5-fd06b4fdd46c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-415d1b2f-5718-4d1f-acb5-fd06b4fdd46c')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-415d1b2f-5718-4d1f-acb5-fd06b4fdd46c button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fde315c5-a44b-417a-9e70-3c7b086074f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fde315c5-a44b-417a-9e70-3c7b086074f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
        "df_test_under.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohrw0IfMRRQi",
        "outputId": "c29f2ced-9952-4a47-dc25-01f302e2d531"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4074, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_under[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "96eV-V_-RLLe",
        "outputId": "7d335df1-01be-48b4-b8a3-76715ec1f094"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CreditScore  Gender       Age  Tenure   Balance  HasCrCard  \\\n",
              "4666        1.000       0  0.283784     0.5  0.456328          1   \n",
              "5145        0.868       1  0.270270     0.1  0.552077          1   \n",
              "7325        0.822       0  0.216216     0.2  0.000000          1   \n",
              "1530        0.522       0  0.108108     0.2  0.428496          1   \n",
              "4820        0.268       0  0.189189     0.3  0.000000          1   \n",
              "\n",
              "      IsActiveMember  EstimatedSalary  Exited  NumOfProducts_1  \\\n",
              "4666               0         0.498437       0                1   \n",
              "5145               1         0.858868       0                1   \n",
              "7325               0         0.306228       0                0   \n",
              "1530               1         0.604008       0                0   \n",
              "4820               1         0.696964       0                0   \n",
              "\n",
              "      NumOfProducts_2  NumOfProducts_3  NumOfProducts_4  \n",
              "4666                0                0                0  \n",
              "5145                0                0                0  \n",
              "7325                1                0                0  \n",
              "1530                1                0                0  \n",
              "4820                1                0                0  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-0e8ba2bc-ef71-41f3-8b4a-b30851d1e878\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>NumOfProducts_1</th>\n",
              "      <th>NumOfProducts_2</th>\n",
              "      <th>NumOfProducts_3</th>\n",
              "      <th>NumOfProducts_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4666</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.283784</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.456328</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.498437</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>0.868</td>\n",
              "      <td>1</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.552077</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.858868</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7325</th>\n",
              "      <td>0.822</td>\n",
              "      <td>0</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.306228</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1530</th>\n",
              "      <td>0.522</td>\n",
              "      <td>0</td>\n",
              "      <td>0.108108</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.428496</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.604008</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4820</th>\n",
              "      <td>0.268</td>\n",
              "      <td>0</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.696964</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e8ba2bc-ef71-41f3-8b4a-b30851d1e878')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-e63989d2-9f45-428d-b0c6-c18f59c86edc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e63989d2-9f45-428d-b0c6-c18f59c86edc')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-e63989d2-9f45-428d-b0c6-c18f59c86edc button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e8ba2bc-ef71-41f3-8b4a-b30851d1e878 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e8ba2bc-ef71-41f3-8b4a-b30851d1e878');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_under.Exited.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my6U_hjrRY0I",
        "outputId": "6aa5e51d-924f-4dd2-922c-24fa04df7839"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2037\n",
              "1    2037\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_test_under.drop('Exited', axis=1)\n",
        "y = df_test_under['Exited']\n",
        "\n",
        "inputs_m1 = train_input(X, y)"
      ],
      "metadata": {
        "id": "llDTe89yRbma"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_m1 = ANN(inputs_m1, 'binary_crossentropy', -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe264HPIRw2v",
        "outputId": "4660d1d2-1fd9-447f-9f37-a11eeb68cf72"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "102/102 [==============================] - 1s 2ms/step - loss: 0.6640 - accuracy: 0.6002\n",
            "Epoch 2/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.6892\n",
            "Epoch 3/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.7076\n",
            "Epoch 4/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7128\n",
            "Epoch 5/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7211\n",
            "Epoch 6/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7257\n",
            "Epoch 7/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7278\n",
            "Epoch 8/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7297\n",
            "Epoch 9/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7340\n",
            "Epoch 10/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5216 - accuracy: 0.7352\n",
            "Epoch 11/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5200 - accuracy: 0.7364\n",
            "Epoch 12/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7410\n",
            "Epoch 13/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5175 - accuracy: 0.7404\n",
            "Epoch 14/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.7373\n",
            "Epoch 15/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.7423\n",
            "Epoch 16/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5155 - accuracy: 0.7419\n",
            "Epoch 17/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5142 - accuracy: 0.7416\n",
            "Epoch 18/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5136 - accuracy: 0.7413\n",
            "Epoch 19/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.7465\n",
            "Epoch 20/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.7493\n",
            "Epoch 21/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.7462\n",
            "Epoch 22/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5124 - accuracy: 0.7441\n",
            "Epoch 23/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.7438\n",
            "Epoch 24/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7493\n",
            "Epoch 25/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5106 - accuracy: 0.7441\n",
            "Epoch 26/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5091 - accuracy: 0.7456\n",
            "Epoch 27/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5090 - accuracy: 0.7438\n",
            "Epoch 28/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5093 - accuracy: 0.7490\n",
            "Epoch 29/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7469\n",
            "Epoch 30/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5092 - accuracy: 0.7459\n",
            "Epoch 31/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5080 - accuracy: 0.7453\n",
            "Epoch 32/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5090 - accuracy: 0.7459\n",
            "Epoch 33/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.7481\n",
            "Epoch 34/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7459\n",
            "Epoch 35/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7426\n",
            "Epoch 36/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5077 - accuracy: 0.7478\n",
            "Epoch 37/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7527\n",
            "Epoch 38/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7481\n",
            "Epoch 39/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.7481\n",
            "Epoch 40/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.7432\n",
            "Epoch 41/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7475\n",
            "Epoch 42/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7450\n",
            "Epoch 43/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7462\n",
            "Epoch 44/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7481\n",
            "Epoch 45/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.7502\n",
            "Epoch 46/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7524\n",
            "Epoch 47/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7496\n",
            "Epoch 48/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.7499\n",
            "Epoch 49/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7456\n",
            "Epoch 50/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5060 - accuracy: 0.7456\n",
            "Epoch 51/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7426\n",
            "Epoch 52/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5053 - accuracy: 0.7478\n",
            "Epoch 53/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7502\n",
            "Epoch 54/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7499\n",
            "Epoch 55/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7502\n",
            "Epoch 56/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.7484\n",
            "Epoch 57/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7499\n",
            "Epoch 58/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7493\n",
            "Epoch 59/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5040 - accuracy: 0.7484\n",
            "Epoch 60/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7478\n",
            "Epoch 61/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.7490\n",
            "Epoch 62/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.7475\n",
            "Epoch 63/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7478\n",
            "Epoch 64/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5040 - accuracy: 0.7459\n",
            "Epoch 65/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.7496\n",
            "Epoch 66/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5040 - accuracy: 0.7505\n",
            "Epoch 67/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.7496\n",
            "Epoch 68/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.7502\n",
            "Epoch 69/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7487\n",
            "Epoch 70/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.7499\n",
            "Epoch 71/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.7496\n",
            "Epoch 72/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.7499\n",
            "Epoch 73/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.7499\n",
            "Epoch 74/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.7502\n",
            "Epoch 75/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.7521\n",
            "Epoch 76/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7465\n",
            "Epoch 77/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 0.7530\n",
            "Epoch 78/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7530\n",
            "Epoch 79/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.7515\n",
            "Epoch 80/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.7539\n",
            "Epoch 81/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.7502\n",
            "Epoch 82/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5018 - accuracy: 0.7499\n",
            "Epoch 83/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7508\n",
            "Epoch 84/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7490\n",
            "Epoch 85/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7487\n",
            "Epoch 86/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.7512\n",
            "Epoch 87/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7521\n",
            "Epoch 88/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7527\n",
            "Epoch 89/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7530\n",
            "Epoch 90/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 0.7490\n",
            "Epoch 91/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7512\n",
            "Epoch 92/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.7505\n",
            "Epoch 93/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7527\n",
            "Epoch 94/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.7527\n",
            "Epoch 95/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7505\n",
            "Epoch 96/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7515\n",
            "Epoch 97/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.7490\n",
            "Epoch 98/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.7524\n",
            "Epoch 99/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.7490\n",
            "Epoch 100/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4994 - accuracy: 0.7548\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7571\n",
            "[0.4783765971660614, 0.7570552229881287]\n",
            "26/26 [==============================] - 0s 1ms/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.82      0.77       408\n",
            "           1       0.79      0.70      0.74       407\n",
            "\n",
            "    accuracy                           0.76       815\n",
            "   macro avg       0.76      0.76      0.76       815\n",
            "weighted avg       0.76      0.76      0.76       815\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 2: Oversampling"
      ],
      "metadata": {
        "id": "JaLD9qndSAKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_class_0, count_class_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izYFblENR4-k",
        "outputId": "a4f60a2e-cb3b-4ebb-b462-92f28ad270c0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7963, 2037)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_class_1_over = df_class_1.sample(count_class_0, replace=True) # gives duplication if value is less than perceived\n",
        "df_class_1_over.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycTKzh1bSDSv",
        "outputId": "018ddca5-7ddf-41db-e66c-7f3ad20a49a1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7963, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_over = pd.concat([df_class_1_over, df_class_0], axis=0)\n",
        "df_test_over.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFg9dXzRSFVh",
        "outputId": "075dacdc-fbb5-4b87-bcc4-91e690c72917"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15926, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_over['Exited'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HByeKjMSWDs",
        "outputId": "454db6f4-2867-456b-e75d-b3f0c173dc5b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    7963\n",
              "0    7963\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_test_over.drop('Exited', axis=1)\n",
        "y = df_test_over['Exited']\n",
        "\n",
        "inputs_m2 = train_input(X, y)"
      ],
      "metadata": {
        "id": "5VmnxeoFSbL8"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_m2 = ANN(inputs_m2, 'binary_crossentropy', -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5LN9ZAwSoh2",
        "outputId": "878edfd1-f776-483e-d476-9293615c70c4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "399/399 [==============================] - 2s 2ms/step - loss: 0.6094 - accuracy: 0.6680\n",
            "Epoch 2/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7265\n",
            "Epoch 3/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.5160 - accuracy: 0.7392\n",
            "Epoch 4/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.5099 - accuracy: 0.7455\n",
            "Epoch 5/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.5062 - accuracy: 0.7480\n",
            "Epoch 6/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.5025 - accuracy: 0.7502\n",
            "Epoch 7/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.7501\n",
            "Epoch 8/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7505\n",
            "Epoch 9/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.7495\n",
            "Epoch 10/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.7524\n",
            "Epoch 11/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7518\n",
            "Epoch 12/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7530\n",
            "Epoch 13/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.7527\n",
            "Epoch 14/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7531\n",
            "Epoch 15/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.7537\n",
            "Epoch 16/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.7520\n",
            "Epoch 17/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4928 - accuracy: 0.7518\n",
            "Epoch 18/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7569\n",
            "Epoch 19/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.7549\n",
            "Epoch 20/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7544\n",
            "Epoch 21/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.7561\n",
            "Epoch 22/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.7568\n",
            "Epoch 23/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.7557\n",
            "Epoch 24/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7545\n",
            "Epoch 25/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.7575\n",
            "Epoch 26/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.7561\n",
            "Epoch 27/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.7550\n",
            "Epoch 28/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4861 - accuracy: 0.7560\n",
            "Epoch 29/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4858 - accuracy: 0.7578\n",
            "Epoch 30/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4854 - accuracy: 0.7582\n",
            "Epoch 31/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4841 - accuracy: 0.7595\n",
            "Epoch 32/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4838 - accuracy: 0.7575\n",
            "Epoch 33/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4840 - accuracy: 0.7597\n",
            "Epoch 34/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 0.7586\n",
            "Epoch 35/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7595\n",
            "Epoch 36/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.7564\n",
            "Epoch 37/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7595\n",
            "Epoch 38/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7593\n",
            "Epoch 39/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7588\n",
            "Epoch 40/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7561\n",
            "Epoch 41/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7600\n",
            "Epoch 42/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7593\n",
            "Epoch 43/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7592\n",
            "Epoch 44/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7578\n",
            "Epoch 45/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7586\n",
            "Epoch 46/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.7583\n",
            "Epoch 47/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7629\n",
            "Epoch 48/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7599\n",
            "Epoch 49/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7605\n",
            "Epoch 50/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7601\n",
            "Epoch 51/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.7576\n",
            "Epoch 52/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4768 - accuracy: 0.7580\n",
            "Epoch 53/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7627\n",
            "Epoch 54/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.7599\n",
            "Epoch 55/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.7582\n",
            "Epoch 56/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4753 - accuracy: 0.7602\n",
            "Epoch 57/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4748 - accuracy: 0.7610\n",
            "Epoch 58/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4750 - accuracy: 0.7589\n",
            "Epoch 59/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4747 - accuracy: 0.7613\n",
            "Epoch 60/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4737 - accuracy: 0.7628\n",
            "Epoch 61/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.7606\n",
            "Epoch 62/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.7600\n",
            "Epoch 63/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.7618\n",
            "Epoch 64/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7598\n",
            "Epoch 65/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7619\n",
            "Epoch 66/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7624\n",
            "Epoch 67/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.7626\n",
            "Epoch 68/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.7629\n",
            "Epoch 69/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7644\n",
            "Epoch 70/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7653\n",
            "Epoch 71/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7638\n",
            "Epoch 72/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.7656\n",
            "Epoch 73/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7653\n",
            "Epoch 74/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7632\n",
            "Epoch 75/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7680\n",
            "Epoch 76/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.7655\n",
            "Epoch 77/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7662\n",
            "Epoch 78/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7664\n",
            "Epoch 79/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7673\n",
            "Epoch 80/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7659\n",
            "Epoch 81/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7660\n",
            "Epoch 82/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7676\n",
            "Epoch 83/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4674 - accuracy: 0.7672\n",
            "Epoch 84/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4665 - accuracy: 0.7677\n",
            "Epoch 85/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4668 - accuracy: 0.7659\n",
            "Epoch 86/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4660 - accuracy: 0.7656\n",
            "Epoch 87/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4654 - accuracy: 0.7696\n",
            "Epoch 88/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.7670\n",
            "Epoch 89/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7672\n",
            "Epoch 90/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7662\n",
            "Epoch 91/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7678\n",
            "Epoch 92/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7691\n",
            "Epoch 93/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7692\n",
            "Epoch 94/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7699\n",
            "Epoch 95/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7688\n",
            "Epoch 96/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7705\n",
            "Epoch 97/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7691\n",
            "Epoch 98/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7687\n",
            "Epoch 99/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7698\n",
            "Epoch 100/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7685\n",
            "100/100 [==============================] - 0s 912us/step - loss: 0.4674 - accuracy: 0.7564\n",
            "[0.46741732954978943, 0.7564343810081482]\n",
            "100/100 [==============================] - 0s 755us/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.81      0.77      1593\n",
            "           1       0.79      0.70      0.74      1593\n",
            "\n",
            "    accuracy                           0.76      3186\n",
            "   macro avg       0.76      0.76      0.76      3186\n",
            "weighted avg       0.76      0.76      0.76      3186\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### METHOD 3: Synthetic Minority Oversampling Technique (SMOTE)"
      ],
      "metadata": {
        "id": "DC8TnmKLUHrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Exited', axis=1)\n",
        "y = df['Exited']"
      ],
      "metadata": {
        "id": "awLe0R1TSzGR"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGLNwqf7UTgl",
        "outputId": "c52ca0e5-cbfe-4831-cfde-9c8a3af276cf"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7963\n",
              "1    2037\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(sampling_strategy='minority')\n",
        "X_sm, y_sm = smote.fit_resample(X, y)\n",
        "\n",
        "y_sm.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5iSTGPHUUkj",
        "outputId": "ae5576a6-865d-4209-a609-84e7938a4645"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    7963\n",
              "0    7963\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_m3 = train_input(X_sm, y_sm)\n",
        "inputs_m3[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-FtQAU-UhLl",
        "outputId": "de5ab43a-fb1f-4563-8fdd-8af557c2f773"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12740, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_m3[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9XxmNuNU3Zn",
        "outputId": "79fd475f-3487-4604-d6cb-5ee68510fa6c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3186, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_m3 = ANN(inputs_m3, 'binary_crossentropy', -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRTT22uyU6sO",
        "outputId": "82d2491a-4f3b-49ba-9d6c-9be8bc675538"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "399/399 [==============================] - 2s 3ms/step - loss: 0.6864 - accuracy: 0.5502\n",
            "Epoch 2/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.5654 - accuracy: 0.7104\n",
            "Epoch 3/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.5239 - accuracy: 0.7309\n",
            "Epoch 4/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 0.7442\n",
            "Epoch 5/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.5018 - accuracy: 0.7496\n",
            "Epoch 6/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7529\n",
            "Epoch 7/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.7547\n",
            "Epoch 8/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4911 - accuracy: 0.7561\n",
            "Epoch 9/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.7590\n",
            "Epoch 10/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7569\n",
            "Epoch 11/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.7597\n",
            "Epoch 12/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7611\n",
            "Epoch 13/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7597\n",
            "Epoch 14/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.7626\n",
            "Epoch 15/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.7626\n",
            "Epoch 16/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4757 - accuracy: 0.7612\n",
            "Epoch 17/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.7629\n",
            "Epoch 18/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7639\n",
            "Epoch 19/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7622\n",
            "Epoch 20/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.7630\n",
            "Epoch 21/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.7633\n",
            "Epoch 22/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7639\n",
            "Epoch 23/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4660 - accuracy: 0.7628\n",
            "Epoch 24/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4647 - accuracy: 0.7648\n",
            "Epoch 25/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4631 - accuracy: 0.7669\n",
            "Epoch 26/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4621 - accuracy: 0.7656\n",
            "Epoch 27/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4612 - accuracy: 0.7687\n",
            "Epoch 28/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7700\n",
            "Epoch 29/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7706\n",
            "Epoch 30/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7718\n",
            "Epoch 31/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.7705\n",
            "Epoch 32/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.7739\n",
            "Epoch 33/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.7706\n",
            "Epoch 34/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7743\n",
            "Epoch 35/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.7748\n",
            "Epoch 36/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7718\n",
            "Epoch 37/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4539 - accuracy: 0.7739\n",
            "Epoch 38/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.7744\n",
            "Epoch 39/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.7750\n",
            "Epoch 40/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7757\n",
            "Epoch 41/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7764\n",
            "Epoch 42/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.7735\n",
            "Epoch 43/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7769\n",
            "Epoch 44/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7758\n",
            "Epoch 45/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7747\n",
            "Epoch 46/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7773\n",
            "Epoch 47/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.7769\n",
            "Epoch 48/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7786\n",
            "Epoch 49/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7786\n",
            "Epoch 50/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4487 - accuracy: 0.7793\n",
            "Epoch 51/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4487 - accuracy: 0.7766\n",
            "Epoch 52/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4481 - accuracy: 0.7765\n",
            "Epoch 53/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4480 - accuracy: 0.7776\n",
            "Epoch 54/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4480 - accuracy: 0.7773\n",
            "Epoch 55/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4481 - accuracy: 0.7781\n",
            "Epoch 56/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7778\n",
            "Epoch 57/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7772\n",
            "Epoch 58/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7768\n",
            "Epoch 59/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.7765\n",
            "Epoch 60/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7767\n",
            "Epoch 61/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7797\n",
            "Epoch 62/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7787\n",
            "Epoch 63/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.7770\n",
            "Epoch 64/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7783\n",
            "Epoch 65/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7784\n",
            "Epoch 66/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7761\n",
            "Epoch 67/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7797\n",
            "Epoch 68/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7785\n",
            "Epoch 69/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7777\n",
            "Epoch 70/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7760\n",
            "Epoch 71/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7774\n",
            "Epoch 72/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7772\n",
            "Epoch 73/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7772\n",
            "Epoch 74/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7766\n",
            "Epoch 75/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7761\n",
            "Epoch 76/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7777\n",
            "Epoch 77/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4459 - accuracy: 0.7761\n",
            "Epoch 78/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4460 - accuracy: 0.7772\n",
            "Epoch 79/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4457 - accuracy: 0.7773\n",
            "Epoch 80/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4458 - accuracy: 0.7776\n",
            "Epoch 81/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4457 - accuracy: 0.7772\n",
            "Epoch 82/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.4461 - accuracy: 0.7784\n",
            "Epoch 83/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.7775\n",
            "Epoch 84/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7786\n",
            "Epoch 85/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.7777\n",
            "Epoch 86/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7801\n",
            "Epoch 87/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7787\n",
            "Epoch 88/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7791\n",
            "Epoch 89/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7794\n",
            "Epoch 90/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.7796\n",
            "Epoch 91/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7794\n",
            "Epoch 92/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7785\n",
            "Epoch 93/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7776\n",
            "Epoch 94/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7796\n",
            "Epoch 95/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.7776\n",
            "Epoch 96/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.7782\n",
            "Epoch 97/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.7783\n",
            "Epoch 98/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7792\n",
            "Epoch 99/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7776\n",
            "Epoch 100/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.7797\n",
            "100/100 [==============================] - 0s 937us/step - loss: 0.4445 - accuracy: 0.7768\n",
            "[0.444491446018219, 0.7768361568450928]\n",
            "100/100 [==============================] - 0s 804us/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.77      0.78      1593\n",
            "           1       0.77      0.78      0.78      1593\n",
            "\n",
            "    accuracy                           0.78      3186\n",
            "   macro avg       0.78      0.78      0.78      3186\n",
            "weighted avg       0.78      0.78      0.78      3186\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 4: Use of Ensemble with undersampling"
      ],
      "metadata": {
        "id": "kZIKmBZ5VSAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.Exited.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fp-ZvALMVdgg",
        "outputId": "404d6529-3582-4415-eadd-66c4cae7061b"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7963\n",
              "1    2037\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Exited', axis=1)\n",
        "y = df['Exited']"
      ],
      "metadata": {
        "id": "XTJYijF6Vq8A"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_batch(df_majority, df_minority, start, end):\n",
        "  df_train = pd.concat([df_majority[start:end], df_minority], axis=0)\n",
        "\n",
        "  X_train = df_train.drop('Exited', axis=1)\n",
        "  y_train = df_train.Exited\n",
        "\n",
        "  return X_train, y_train"
      ],
      "metadata": {
        "id": "yjNQdBDTVCCY"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
      ],
      "metadata": {
        "id": "697OxvT4WAMo"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ANN(X_train, y_train, X_test, y_test, loss, weights):\n",
        "  model = keras.Sequential([\n",
        "      keras.layers.Dense(10, input_shape=(12,), activation='relu'),\n",
        "      keras.layers.Dense(5, input_shape=(12,), activation='relu'),\n",
        "      keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "      optimizer='adam',\n",
        "      loss='binary_crossentropy',\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  if weights == -1:\n",
        "    model.fit(X_train, y_train, epochs=100)\n",
        "  else:\n",
        "    model.fit(X_train, y_train, epochs=100, class_weight = weights)\n",
        "\n",
        "  print(model.evaluate(X_test, y_test))\n",
        "\n",
        "  y_preds = model.predict(X_test)\n",
        "  y_pred = np.round(y_preds)\n",
        "\n",
        "  print(\"Classification Report: \\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "  return y_preds"
      ],
      "metadata": {
        "id": "o0vme9VmVaee"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9xRxThNWQp2",
        "outputId": "08fb2adb-6d56-4dac-c7ed-e9e4fd6739dc"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6370\n",
              "1    1630\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "6370/1630"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sdh9D7RWWrO",
        "outputId": "4f43a949-08ae-47dd-b151-176674bfaee8"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.9079754601226995"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "6370/3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h_P7in2WahV",
        "outputId": "2114a87c-deda-45dd-ce05-5db738629053"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2123.3333333333335"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2100+2100+2170"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bKvhEqTXbYG",
        "outputId": "ab74b456-1167-4d31-e3a7-a90776bd9831"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6370"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = X_train.copy()\n",
        "df2['Exited'] = y_train\n",
        "\n",
        "df2_class0 = df2[df2.Exited==0]\n",
        "df2_class1 = df2[df2.Exited==1]\n",
        "\n",
        "df2_class0.shape, df2_class1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaRbc4y9Wn1P",
        "outputId": "1c65153c-d1be-4e8c-e3cc-56e3f45d1afe"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6370, 13), (1630, 13))"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = get_train_batch(df2_class0, df2_class1, 0, 2100)\n",
        "y_pred_m4_1 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXjZ29gVWGiB",
        "outputId": "ecc21506-2ef3-4558-922a-87031b788b12"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "117/117 [==============================] - 1s 1ms/step - loss: 0.6727 - accuracy: 0.6097\n",
            "Epoch 2/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.6209 - accuracy: 0.6826\n",
            "Epoch 3/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5855 - accuracy: 0.6962\n",
            "Epoch 4/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7008\n",
            "Epoch 5/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.7113\n",
            "Epoch 6/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5446 - accuracy: 0.7169\n",
            "Epoch 7/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5376 - accuracy: 0.7249\n",
            "Epoch 8/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5328 - accuracy: 0.7244\n",
            "Epoch 9/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5275 - accuracy: 0.7263\n",
            "Epoch 10/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5243 - accuracy: 0.7314\n",
            "Epoch 11/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.7370\n",
            "Epoch 12/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5184 - accuracy: 0.7359\n",
            "Epoch 13/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5180 - accuracy: 0.7343\n",
            "Epoch 14/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5150 - accuracy: 0.7381\n",
            "Epoch 15/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.7383\n",
            "Epoch 16/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5135 - accuracy: 0.7450\n",
            "Epoch 17/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.7410\n",
            "Epoch 18/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7418\n",
            "Epoch 19/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5110 - accuracy: 0.7383\n",
            "Epoch 20/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5110 - accuracy: 0.7418\n",
            "Epoch 21/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7437\n",
            "Epoch 22/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.7424\n",
            "Epoch 23/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.7413\n",
            "Epoch 24/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7464\n",
            "Epoch 25/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.7437\n",
            "Epoch 26/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7450\n",
            "Epoch 27/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7434\n",
            "Epoch 28/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7408\n",
            "Epoch 29/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7437\n",
            "Epoch 30/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5070 - accuracy: 0.7496\n",
            "Epoch 31/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7437\n",
            "Epoch 32/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7437\n",
            "Epoch 33/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7461\n",
            "Epoch 34/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7464\n",
            "Epoch 35/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7434\n",
            "Epoch 36/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7426\n",
            "Epoch 37/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7477\n",
            "Epoch 38/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7456\n",
            "Epoch 39/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7445\n",
            "Epoch 40/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.7426\n",
            "Epoch 41/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7499\n",
            "Epoch 42/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7469\n",
            "Epoch 43/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5035 - accuracy: 0.7477\n",
            "Epoch 44/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.7450\n",
            "Epoch 45/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5040 - accuracy: 0.7499\n",
            "Epoch 46/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.7448\n",
            "Epoch 47/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.7480\n",
            "Epoch 48/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.7496\n",
            "Epoch 49/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.7458\n",
            "Epoch 50/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.7480\n",
            "Epoch 51/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.7448\n",
            "Epoch 52/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.7458\n",
            "Epoch 53/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.7453\n",
            "Epoch 54/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7531\n",
            "Epoch 55/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.7480\n",
            "Epoch 56/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.7453\n",
            "Epoch 57/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.7456\n",
            "Epoch 58/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.7501\n",
            "Epoch 59/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5008 - accuracy: 0.7461\n",
            "Epoch 60/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.7504\n",
            "Epoch 61/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7504\n",
            "Epoch 62/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5000 - accuracy: 0.7466\n",
            "Epoch 63/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.7480\n",
            "Epoch 64/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4994 - accuracy: 0.7483\n",
            "Epoch 65/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.7442\n",
            "Epoch 66/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.7499\n",
            "Epoch 67/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.7469\n",
            "Epoch 68/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.7493\n",
            "Epoch 69/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.7485\n",
            "Epoch 70/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.7448\n",
            "Epoch 71/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.7472\n",
            "Epoch 72/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.7493\n",
            "Epoch 73/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.7504\n",
            "Epoch 74/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7480\n",
            "Epoch 75/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.7504\n",
            "Epoch 76/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.7493\n",
            "Epoch 77/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7469\n",
            "Epoch 78/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5008 - accuracy: 0.7440\n",
            "Epoch 79/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.7466\n",
            "Epoch 80/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.7507\n",
            "Epoch 81/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4977 - accuracy: 0.7485\n",
            "Epoch 82/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.7491\n",
            "Epoch 83/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.7485\n",
            "Epoch 84/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.7517\n",
            "Epoch 85/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.7515\n",
            "Epoch 86/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.7507\n",
            "Epoch 87/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.7509\n",
            "Epoch 88/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7477\n",
            "Epoch 89/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.7477\n",
            "Epoch 90/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7539\n",
            "Epoch 91/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.7512\n",
            "Epoch 92/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7480\n",
            "Epoch 93/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4941 - accuracy: 0.7531\n",
            "Epoch 94/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.7536\n",
            "Epoch 95/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.7528\n",
            "Epoch 96/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.7520\n",
            "Epoch 97/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7534\n",
            "Epoch 98/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.7550\n",
            "Epoch 99/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7536\n",
            "Epoch 100/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7544\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7895\n",
            "[0.4369364380836487, 0.7894999980926514]\n",
            "63/63 [==============================] - 0s 4ms/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.82      0.86      1593\n",
            "           1       0.49      0.66      0.56       407\n",
            "\n",
            "    accuracy                           0.79      2000\n",
            "   macro avg       0.70      0.74      0.71      2000\n",
            "weighted avg       0.82      0.79      0.80      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = get_train_batch(df2_class0, df2_class1, 2100, 4200)\n",
        "y_pred_m4_2 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGQXfFYFW9GC",
        "outputId": "a4160909-24dc-4a0b-9eeb-87dbadb92b4c"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "117/117 [==============================] - 1s 1ms/step - loss: 0.6740 - accuracy: 0.5568\n",
            "Epoch 2/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.6231 - accuracy: 0.6252\n",
            "Epoch 3/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.6836\n",
            "Epoch 4/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5776 - accuracy: 0.7038\n",
            "Epoch 5/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7080\n",
            "Epoch 6/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5482 - accuracy: 0.7126\n",
            "Epoch 7/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5378 - accuracy: 0.7182\n",
            "Epoch 8/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7231\n",
            "Epoch 9/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7263\n",
            "Epoch 10/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7362\n",
            "Epoch 11/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7349\n",
            "Epoch 12/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7408\n",
            "Epoch 13/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7410\n",
            "Epoch 14/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7429\n",
            "Epoch 15/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7432\n",
            "Epoch 16/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7424\n",
            "Epoch 17/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.7453\n",
            "Epoch 18/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7458\n",
            "Epoch 19/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.7458\n",
            "Epoch 20/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7475\n",
            "Epoch 21/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7456\n",
            "Epoch 22/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7429\n",
            "Epoch 23/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.7483\n",
            "Epoch 24/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.7472\n",
            "Epoch 25/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.7464\n",
            "Epoch 26/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7469\n",
            "Epoch 27/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7464\n",
            "Epoch 28/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4976 - accuracy: 0.7464\n",
            "Epoch 29/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7472\n",
            "Epoch 30/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.7493\n",
            "Epoch 31/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7466\n",
            "Epoch 32/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.7480\n",
            "Epoch 33/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7531\n",
            "Epoch 34/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.7544\n",
            "Epoch 35/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7509\n",
            "Epoch 36/100\n",
            "117/117 [==============================] - 1s 6ms/step - loss: 0.4923 - accuracy: 0.7499\n",
            "Epoch 37/100\n",
            "117/117 [==============================] - 1s 5ms/step - loss: 0.4922 - accuracy: 0.7523\n",
            "Epoch 38/100\n",
            "117/117 [==============================] - 1s 5ms/step - loss: 0.4916 - accuracy: 0.7512\n",
            "Epoch 39/100\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7523\n",
            "Epoch 40/100\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7534\n",
            "Epoch 41/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.7550\n",
            "Epoch 42/100\n",
            "117/117 [==============================] - 1s 6ms/step - loss: 0.4903 - accuracy: 0.7525\n",
            "Epoch 43/100\n",
            "117/117 [==============================] - 1s 6ms/step - loss: 0.4890 - accuracy: 0.7544\n",
            "Epoch 44/100\n",
            "117/117 [==============================] - 1s 6ms/step - loss: 0.4883 - accuracy: 0.7555\n",
            "Epoch 45/100\n",
            "117/117 [==============================] - 1s 5ms/step - loss: 0.4877 - accuracy: 0.7539\n",
            "Epoch 46/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7528\n",
            "Epoch 47/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7542\n",
            "Epoch 48/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7584\n",
            "Epoch 49/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7531\n",
            "Epoch 50/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7568\n",
            "Epoch 51/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7517\n",
            "Epoch 52/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7566\n",
            "Epoch 53/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7547\n",
            "Epoch 54/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7563\n",
            "Epoch 55/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7544\n",
            "Epoch 56/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7587\n",
            "Epoch 57/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7558\n",
            "Epoch 58/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.7574\n",
            "Epoch 59/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7587\n",
            "Epoch 60/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7587\n",
            "Epoch 61/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7571\n",
            "Epoch 62/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.7576\n",
            "Epoch 63/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7534\n",
            "Epoch 64/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7603\n",
            "Epoch 65/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7592\n",
            "Epoch 66/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7571\n",
            "Epoch 67/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7592\n",
            "Epoch 68/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7603\n",
            "Epoch 69/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7587\n",
            "Epoch 70/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7595\n",
            "Epoch 71/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7592\n",
            "Epoch 72/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7584\n",
            "Epoch 73/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7611\n",
            "Epoch 74/100\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7622\n",
            "Epoch 75/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7598\n",
            "Epoch 76/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7568\n",
            "Epoch 77/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7646\n",
            "Epoch 78/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7598\n",
            "Epoch 79/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7603\n",
            "Epoch 80/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7574\n",
            "Epoch 81/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7598\n",
            "Epoch 82/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.7646\n",
            "Epoch 83/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7603\n",
            "Epoch 84/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7617\n",
            "Epoch 85/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7606\n",
            "Epoch 86/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7614\n",
            "Epoch 87/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7643\n",
            "Epoch 88/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7592\n",
            "Epoch 89/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7619\n",
            "Epoch 90/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7601\n",
            "Epoch 91/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7609\n",
            "Epoch 92/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7606\n",
            "Epoch 93/100\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7630\n",
            "Epoch 94/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7622\n",
            "Epoch 95/100\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7627\n",
            "Epoch 96/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.7606\n",
            "Epoch 97/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.7568\n",
            "Epoch 98/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.7635\n",
            "Epoch 99/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.7574\n",
            "Epoch 100/100\n",
            "117/117 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.7611\n",
            "63/63 [==============================] - 0s 950us/step - loss: 0.4017 - accuracy: 0.8180\n",
            "[0.4016566574573517, 0.8180000185966492]\n",
            "63/63 [==============================] - 0s 930us/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.88      0.89      1593\n",
            "           1       0.55      0.58      0.56       407\n",
            "\n",
            "    accuracy                           0.82      2000\n",
            "   macro avg       0.72      0.73      0.72      2000\n",
            "weighted avg       0.82      0.82      0.82      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = get_train_batch(df2_class0, df2_class1, 4200, 6370)\n",
        "y_pred_m4_3 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW9AegDwXGxQ",
        "outputId": "a004a56e-c394-4ead-a5ab-def994bb2e9c"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "119/119 [==============================] - 1s 1ms/step - loss: 0.6819 - accuracy: 0.6371\n",
            "Epoch 2/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.6223 - accuracy: 0.6874\n",
            "Epoch 3/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.5738 - accuracy: 0.7034\n",
            "Epoch 4/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.5547 - accuracy: 0.7113\n",
            "Epoch 5/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.5416 - accuracy: 0.7184\n",
            "Epoch 6/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.5339 - accuracy: 0.7279\n",
            "Epoch 7/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.5271 - accuracy: 0.7292\n",
            "Epoch 8/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.5215 - accuracy: 0.7345\n",
            "Epoch 9/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7371\n",
            "Epoch 10/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.5143 - accuracy: 0.7403\n",
            "Epoch 11/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.7479\n",
            "Epoch 12/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.7447\n",
            "Epoch 13/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.7482\n",
            "Epoch 14/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.7497\n",
            "Epoch 15/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.7518\n",
            "Epoch 16/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.7539\n",
            "Epoch 17/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.5005 - accuracy: 0.7571\n",
            "Epoch 18/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.7550\n",
            "Epoch 19/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4983 - accuracy: 0.7582\n",
            "Epoch 20/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7579\n",
            "Epoch 21/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.7537\n",
            "Epoch 22/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7608\n",
            "Epoch 23/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.7626\n",
            "Epoch 24/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7603\n",
            "Epoch 25/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.7645\n",
            "Epoch 26/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.7597\n",
            "Epoch 27/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.7624\n",
            "Epoch 28/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.7626\n",
            "Epoch 29/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.7621\n",
            "Epoch 30/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.7616\n",
            "Epoch 31/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.7655\n",
            "Epoch 32/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7650\n",
            "Epoch 33/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.7645\n",
            "Epoch 34/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.7639\n",
            "Epoch 35/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.7661\n",
            "Epoch 36/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7687\n",
            "Epoch 37/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7634\n",
            "Epoch 38/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.7634\n",
            "Epoch 39/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.7682\n",
            "Epoch 40/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.7621\n",
            "Epoch 41/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.7663\n",
            "Epoch 42/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7639\n",
            "Epoch 43/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7655\n",
            "Epoch 44/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7634\n",
            "Epoch 45/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7682\n",
            "Epoch 46/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7637\n",
            "Epoch 47/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7653\n",
            "Epoch 48/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.7637\n",
            "Epoch 49/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.7666\n",
            "Epoch 50/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7668\n",
            "Epoch 51/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7666\n",
            "Epoch 52/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7642\n",
            "Epoch 53/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7637\n",
            "Epoch 54/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7655\n",
            "Epoch 55/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7639\n",
            "Epoch 56/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7661\n",
            "Epoch 57/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7653\n",
            "Epoch 58/100\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7632\n",
            "Epoch 59/100\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7637\n",
            "Epoch 60/100\n",
            "119/119 [==============================] - 1s 4ms/step - loss: 0.4781 - accuracy: 0.7642\n",
            "Epoch 61/100\n",
            "119/119 [==============================] - 1s 4ms/step - loss: 0.4780 - accuracy: 0.7634\n",
            "Epoch 62/100\n",
            "119/119 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7645\n",
            "Epoch 63/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7639\n",
            "Epoch 64/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7637\n",
            "Epoch 65/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7613\n",
            "Epoch 66/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.7634\n",
            "Epoch 67/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.7634\n",
            "Epoch 68/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7658\n",
            "Epoch 69/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7647\n",
            "Epoch 70/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7653\n",
            "Epoch 71/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7634\n",
            "Epoch 72/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7689\n",
            "Epoch 73/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7613\n",
            "Epoch 74/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.7647\n",
            "Epoch 75/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7661\n",
            "Epoch 76/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7645\n",
            "Epoch 77/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7674\n",
            "Epoch 78/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7616\n",
            "Epoch 79/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.7613\n",
            "Epoch 80/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.7626\n",
            "Epoch 81/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7634\n",
            "Epoch 82/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7626\n",
            "Epoch 83/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4763 - accuracy: 0.7663\n",
            "Epoch 84/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7605\n",
            "Epoch 85/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4769 - accuracy: 0.7629\n",
            "Epoch 86/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.7605\n",
            "Epoch 87/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.7626\n",
            "Epoch 88/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7661\n",
            "Epoch 89/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7639\n",
            "Epoch 90/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4761 - accuracy: 0.7629\n",
            "Epoch 91/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.7658\n",
            "Epoch 92/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7618\n",
            "Epoch 93/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7589\n",
            "Epoch 94/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7618\n",
            "Epoch 95/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.7634\n",
            "Epoch 96/100\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.7624\n",
            "Epoch 97/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7642\n",
            "Epoch 98/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7655\n",
            "Epoch 99/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7629\n",
            "Epoch 100/100\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7676\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7820\n",
            "[0.4563123285770416, 0.7820000052452087]\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.80      0.85      1593\n",
            "           1       0.48      0.70      0.57       407\n",
            "\n",
            "    accuracy                           0.78      2000\n",
            "   macro avg       0.69      0.75      0.71      2000\n",
            "weighted avg       0.82      0.78      0.80      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(y_pred_m4_1))\n",
        "print(len(y_pred_m4_2))\n",
        "print(len(y_pred_m4_3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC7j9-ZFYPiH",
        "outputId": "3e0c2626-f604-486b-c2fb-2f13bc57ea0c"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n",
            "2000\n",
            "2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_final = y_pred_m4_1.copy()\n",
        "\n",
        "for i in range(len(y_pred_m4_1)):\n",
        "  n_ones = y_pred_m4_1[i] + y_pred_m4_2[i] + y_pred_m4_3[i]\n",
        "\n",
        "  if n_ones > 1:\n",
        "    y_pred_final[i] = 1\n",
        "  else:\n",
        "    y_pred_final[i] = 0"
      ],
      "metadata": {
        "id": "iKRL67XbYc-6"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sat6QOiYYj9K",
        "outputId": "2945cec1-2017-4fb6-f9f3-8babe69efed6"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       ...,\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred_final))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBFjx9JoYyRa",
        "outputId": "419ebccf-ddfd-4405-d745-536335a40b89"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.65      0.77      1593\n",
            "           1       0.38      0.85      0.53       407\n",
            "\n",
            "    accuracy                           0.69      2000\n",
            "   macro avg       0.66      0.75      0.65      2000\n",
            "weighted avg       0.83      0.69      0.72      2000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}